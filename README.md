# Awesome-Efficient-Deep-Learning

## Courses
TinyML and Efficient Deep Learning Computing (6.5940 • Fall • 2023) • https://efficientml.ai

## Knowledge Distillation

- 2022-ECCV-[CMKD: Cross-Modality Knowledge Distillation Network for Monocular 3D Object Detection](https://github.com/Cc-Hy/CMKD) 

- 2023-CVPR-[UniDistill: A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in Bird's-Eye View](https://github.com/megvii-research/CVPR2023-UniDistill?tab=readme-ov-file#unidistill-a-universal-cross-modality-knowledge-distillation-framework-for-3d-object-detection-in-birds-eye-view)

## TinyML

- 2020-NeurIPS-[TinyTL: Reduce Activations, Not Trainable Parameters for Efficient On-Device Learning](https://hanlab.mit.edu/projects/tinytl) 

- 2020-NeurIPS-[MCUNet: Tiny Deep Learning on IoT Devices](https://hanlab.mit.edu/projects/mcunet) [‍](https://hanlab.mit.edu/projects/mcunetv2)

- 2021-NeurIPS-[MCUNetV2: Memory-Efficient Patch-based Inference for Tiny Deep Learning](https://hanlab.mit.edu/projects/mcunetv2) [‍](https://hanlab.mit.edu/projects/mcunetv3)

- 2022-NeurIPS-[MCUNetV3: On-Device Training Under 256KB Memory](https://hanlab.mit.edu/projects/mcunetv3)[‍](https://hanlab.mit.edu/projects/tinytl)

  

## 

